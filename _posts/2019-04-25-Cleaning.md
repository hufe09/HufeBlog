---
layout: post
title: "「数据分析」Module 04: Cleaning Data"
subtitle: 'Data Analysis : Data Wrangling'
author: "Hufe"
header-img: "img/post-bg-python.jpg"
header-mask: 0.3
mathjax: true
tags:
  - Python
  - Data Analysis
---
# Assessing

## Gather


```python
import pandas as pd
import numpy as np
```


```python
patients = pd.read_csv('../Assess/patients.csv')
treatments = pd.read_csv('../Assess/treatments.csv')
adverse_reactions = pd.read_csv('../Assess/adverse_reactions.csv')
```

## Access

### Quality
#####  *`treatment`表*
- 丢失数据(应该350名患者，实际280)
- 缺少hba1c_change
- 'auralin`和`novodra`列中的起始剂量和最终剂量旁边的'u'
- 小写名称
- 错误数据类型（zip_code, assigned sex, state, birthday）
- 错误的HbA1c change

##### `patients`表
- zip_code格式不佳（例如，四位数和浮点数据类型而不是五位数字和字符串或对象数据类型）
- 患者身高值不正确（例如，Tim Neudorf身高27英寸而不是72英寸）
- state不一致(有时是完整的州名，有时是缩写)
- Dsvid 拼写错误，应该是David
- 错误数据类型（auranlin and novodra colums）
- 话号码格式不一致
- 有不可恢复的无名氏记录
- Jakobsen, Gersten, Taylor有多项记录
- Zaitseva的重量单位是“kgs”而不是“lbs”（磅）

##### `adverse_reactions`表
- 小写名称

### Tidiness
- 联系人列表中，电话和邮箱应该分为两列
- 治疗表中，将auranlin and novodra 分为三个变量（treatment, start does and end does）

## Clean

![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/26/1556209407985-1556209407997.png)

### copy一份原数据，命名为*_clean


```python
patients_clean = patients.copy()
# patients_clean
```


```python
treatments_clean = treatments.copy()
# treatments_clean
```


```python
adverse_reactions_clean = adverse_reactions.copy()
# adverse_reactions_clean
```

### Clean for [Tidiness]

#### 联系人列表中，电话和邮箱应该分为两列

*pandas.Series.str.extract [来源]*  
`Series.str.extract(pat, flags=0, expand=True)`  

对于系列中的每个主题字符串，从正则表达式pat的第一个匹配中提取组。  

**参数：**	
- `pat` ： 字符串
具有捕获组的正则表达式模式。

- `flags` ： int，默认为0（无标志）
来自re模块的标志，例如re.IGNORECASE，修改正则表达式匹配，例如大小写，空格等。有关详细信息，请参阅re。

- `expand` ： bool，默认为True
如果为True，则返回DataFrame，每个捕获组一列。如果为False，如果有一个捕获组，则返回系列/索引;如果有多个捕获组，则返回DataFrame。

**返回：**	
**DataFrame或系列或索引**  
一个DataFrame，每个主题字符串有一行，每个组有一列。正则表达式pat中的任何捕获组名称都将用于列名称; 否则将使用捕获组编号。即使找不到匹配项，每个结果列的dtype也始终为object。如果 expand=False和pat只有一个捕获组，则返回一个系列（如果主题是系列）或索引（如果主题是索引）。

- phone_number
    - str.extract(regEx, expand=True) return a new DataFrame with n columns(defined by the number of group in regEx).
    - (
    - (?: : left paren will not count as a group result.
    - \+\d{1,2}\s)?
    - \(?
    - \d{3}
    - \)?
    - [\s.-]?\d{3}[\s.-]?\d{4}
    - )


```python
patients_clean['phone_number'] = patients_clean.contact.str.extract('((?:\+\d{1,2}\s)?\(?\d{3}\)?[\s.-]?\d{3}[\s.-]\d{4})', expand=True)
patients_clean['phone_number'].head(5)
```




    0         951-719-9170
    1    +1 (217) 569-3204
    2         402-363-6804
    3    +1 (732) 636-8246
    4         334-515-7487
    Name: phone_number, dtype: object



- email
    - str.extract(regEx, expand=True) return a new DataFrame with n columns(defined by the number of group in regEx).
    - (
    - [a-zA-Z][a-zA-Z0-9_.+-]+
    - @[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+[a-zA-Z]
    - )


```python
patients_clean['email'] = patients_clean.contact.str.extract('([a-zA-Z][a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+[a-zA-Z])', expand=True)
patients_clean['email'].sample(3)
```




    143    AmandaCavalcantiRibeiro@fleckens.hu
    476              BertaNapolitani@rhyta.com
    226              KariHervinsson@einrot.com
    Name: email, dtype: object



- 删除原数据


```python
patients_clean = patients_clean.drop('contact', axis=1)
patients_clean.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 503 entries, 0 to 502
    Data columns (total 15 columns):
    patient_id      503 non-null int64
    assigned_sex    503 non-null object
    given_name      503 non-null object
    surname         503 non-null object
    address         491 non-null object
    city            491 non-null object
    state           491 non-null object
    zip_code        491 non-null float64
    country         491 non-null object
    birthdate       503 non-null object
    weight          503 non-null float64
    height          503 non-null int64
    bmi             503 non-null float64
    phone_number    485 non-null object
    email           491 non-null object
    dtypes: float64(3), int64(2), object(10)
    memory usage: 59.0+ KB


#### 治疗表中，将auranlin and novodra 分为三个变量（treatment, start does and end does）

*pandas.melt [源]*  
`pandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)`  
将DataFrame从宽格式展开为长格式，可选择保留标识符变量集。  

此函数可用于将DataFrame按压为一个或多个列为标识符变量（id_vars）的格式，而所有其他列（被视为测量变量（value_vars））对行轴“未分配”，只留下两个非标识符列，'变量'和'值'。

**参数：**	
- **`frame`** ： DataFrame
- **`id_vars`** ： tuple，list或ndarray，可选
用作标识符变量的列。

- **`value_vars`** ： tuple，list或ndarray，可选
要拆开的列。如果未指定，则使用未设置为id_vars的所有列。

- **`var_name`** ： 标量
用于“变量”列的名称。如果没有它使用 frame.columns.name或'变量'。

- **`value_name`** ： 标量，默认值'value'
用于“值”列的名称。

- **`col_level`** ： int或string，可选
如果列是MultiIndex，则使用此级别进行融合。

- From Wide to Long
- `df2 = pd.melt(df, id_vars=['unaffected_col', 'unaffected_col', ..], var_name="categorical_col", value_name="numerical_col")`
- str.split(str='', num=n)
    - str: This is any delimeter, by default it is space.
    - num: this is number of lines minus one


```python
treatments_clean = pd.melt(treatments_clean, 
                id_vars=['given_name', 'surname', 'hba1c_start', 'hba1c_end', 'hba1c_change'],
                var_name = 'treatment', value_name='does')
treatments_clean = treatments_clean[treatments_clean.does != '-']
treatments_clean['does_start'],treatments_clean['does_end'] = treatments_clean['does'].str.split(' - ', 1).str
treatments_clean =treatments_clean.drop('does', axis = 1)
```

- 分割`u`,并转换为整数： `Series.str.strip('u').astype(int)`


```python
treatments_clean.does_start = treatments_clean.does_start.str.strip('u').astype(int)
treatments_clean.does_end = treatments_clean.does_end.str.strip('u').astype(int)
```

- `treatments`表，计算剂量改变


```python
treatments_clean["does_change"] = treatments_clean["does_start"] - treatments_clean["does_end"]
```


```python
treatments_clean.head()
```



<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>given_name</th>
      <th>surname</th>
      <th>hba1c_start</th>
      <th>hba1c_end</th>
      <th>hba1c_change</th>
      <th>treatment</th>
      <th>does_start</th>
      <th>does_end</th>
      <th>does_change</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>veronika</td>
      <td>jindrová</td>
      <td>7.63</td>
      <td>7.20</td>
      <td>NaN</td>
      <td>auralin</td>
      <td>41</td>
      <td>48</td>
      <td>-7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>skye</td>
      <td>gormanston</td>
      <td>7.97</td>
      <td>7.62</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>33</td>
      <td>36</td>
      <td>-3</td>
    </tr>
    <tr>
      <th>6</th>
      <td>sophia</td>
      <td>haugen</td>
      <td>7.65</td>
      <td>7.27</td>
      <td>0.38</td>
      <td>auralin</td>
      <td>37</td>
      <td>42</td>
      <td>-5</td>
    </tr>
    <tr>
      <th>7</th>
      <td>eddie</td>
      <td>archer</td>
      <td>7.89</td>
      <td>7.55</td>
      <td>0.34</td>
      <td>auralin</td>
      <td>31</td>
      <td>38</td>
      <td>-7</td>
    </tr>
    <tr>
      <th>9</th>
      <td>asia</td>
      <td>woźniak</td>
      <td>7.76</td>
      <td>7.37</td>
      <td>NaN</td>
      <td>auralin</td>
      <td>30</td>
      <td>36</td>
      <td>-6</td>
    </tr>
  </tbody>
</table>




#### 不良反应表应该是治疗表的一部分

- pd.concat(): when sharing **the same column-names**
    - df_new = pd.concat([df_a, df_b]): stacking vertically.
    - df_new = pd.concat([df_a, df_b], axis=1): stacking horizontally(..so repeated columns)
    - *df_a.append(df_b, ignore_index=True): stacking vertically.
- pd.merge(): when having **different column-names**. It requires the common'key'(ID) columns.
    - df_new2 = pd.merge(df_new, df_c, on='id', how='inner'/'outer'/'left'/'right')
- df.join(): when having **different column-names** but W/O common 'key' columns and 'differently-indexed'.
    - df_new3 = df_new2.join(df_d)


```python
treatments_clean = pd.merge(treatments_clean, adverse_reactions_clean, 
                            on=['given_name', 'surname'], how='left')
treatments_clean.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>given_name</th>
      <th>surname</th>
      <th>hba1c_start</th>
      <th>hba1c_end</th>
      <th>hba1c_change</th>
      <th>treatment</th>
      <th>does_start</th>
      <th>does_end</th>
      <th>does_change</th>
      <th>adverse_reaction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>veronika</td>
      <td>jindrová</td>
      <td>7.63</td>
      <td>7.20</td>
      <td>NaN</td>
      <td>auralin</td>
      <td>41</td>
      <td>48</td>
      <td>-7</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>skye</td>
      <td>gormanston</td>
      <td>7.97</td>
      <td>7.62</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>33</td>
      <td>36</td>
      <td>-3</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>sophia</td>
      <td>haugen</td>
      <td>7.65</td>
      <td>7.27</td>
      <td>0.38</td>
      <td>auralin</td>
      <td>37</td>
      <td>42</td>
      <td>-5</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>eddie</td>
      <td>archer</td>
      <td>7.89</td>
      <td>7.55</td>
      <td>0.34</td>
      <td>auralin</td>
      <td>31</td>
      <td>38</td>
      <td>-7</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>asia</td>
      <td>woźniak</td>
      <td>7.76</td>
      <td>7.37</td>
      <td>NaN</td>
      <td>auralin</td>
      <td>30</td>
      <td>36</td>
      <td>-6</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
treatments_clean.adverse_reaction.value_counts()
```




    hypoglycemia                 18
    headache                      3
    injection site discomfort     2
    throat irritation             2
    cough                         1
    nausea                        1
    Name: adverse_reaction, dtype: int64



#### 在患者，治疗和不良反应表中，“given_name”和“surname”栏是重复的
`df.drop(['row_a', 'row_b'])`: 根据列名删除列
`df.frop(df.index[0], inplace = True)`: 根据索引删除列
`df.drop['col_c'], axis=1, inplace = True`：根据列名删除列


```python
id_names = patients_clean[['patient_id', 'given_name', 'surname']]
id_names['given_name'] = id_names['given_name'].str.lower()
id_names['surname'] = id_names['surname'].str.lower()
treatments_clean = pd.merge(treatments_clean, id_names, on=['given_name', 'surname'])
treatments_clean = treatments_clean.drop(['given_name', 'surname'], axis=1)
```

    E:\ProgramData\Anaconda3\envs\data_analysis\lib\site-packages\ipykernel_launcher.py:2: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      
    E:\ProgramData\Anaconda3\envs\data_analysis\lib\site-packages\ipykernel_launcher.py:3: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      This is separate from the ipykernel package so we can avoid doing imports until


#### Patient ID 应该为单独列，不能重复


```python
all_colums = pd.Series(list(patients_clean) + list(treatments_clean))
all_colums[all_colums.duplicated()]
```




    23    patient_id
    dtype: object



### Clean for [Quality]

#### 修复缺失值1

- `treatments`表中，丢失数据(应该350名患者，实际280)  
   - 假设丢失的数据存储在我们本地名为`treatments_cut`的df中。  
   - 一般来说，我们使用`df.dropna(subset=['col','col'...], inplace=True)`   
   -  => “treatments_cut.csv”导入数据帧，并将其与原始治疗数据帧连接。


```python
# treatments_cut = pd.read_csv('treatments.csv')
```


```python
# treatments_clean = pd.concat([treatments_clean, treatments_cut], ignore_index= True)
# treatments_clean
```

- `treatments`表中，缺少`hba1c_change` 
    - => 重新计算`hba1c_change`列: `hba1c_start` - `hba1c_end`


```python
treatments_clean.hba1c_change = (treatments_clean.hba1c_start - treatments_clean.hba1c_end)
treatments_clean.hba1c_change.head()
treatments_clean.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hba1c_start</th>
      <th>hba1c_end</th>
      <th>hba1c_change</th>
      <th>treatment</th>
      <th>does_start</th>
      <th>does_end</th>
      <th>does_change</th>
      <th>adverse_reaction</th>
      <th>patient_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.63</td>
      <td>7.20</td>
      <td>0.43</td>
      <td>auralin</td>
      <td>41</td>
      <td>48</td>
      <td>-7</td>
      <td>NaN</td>
      <td>225</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.97</td>
      <td>7.62</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>33</td>
      <td>36</td>
      <td>-3</td>
      <td>NaN</td>
      <td>242</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.65</td>
      <td>7.27</td>
      <td>0.38</td>
      <td>auralin</td>
      <td>37</td>
      <td>42</td>
      <td>-5</td>
      <td>NaN</td>
      <td>345</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.89</td>
      <td>7.55</td>
      <td>0.34</td>
      <td>auralin</td>
      <td>31</td>
      <td>38</td>
      <td>-7</td>
      <td>NaN</td>
      <td>276</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.76</td>
      <td>7.37</td>
      <td>0.39</td>
      <td>auralin</td>
      <td>30</td>
      <td>36</td>
      <td>-6</td>
      <td>NaN</td>
      <td>15</td>
    </tr>
  </tbody>
</table>
</div>



#### 修复数据类型

 - `patients`表中
     - => 将邮政编码列的数据类型从浮点数转换为字符串使用`Series.astype()`
     - => 使用字符串切片`str[:-2]`删除`“.0”`，并使用前导0填充四位数邮政编码
         - `Series.str.pad(width, side='left', fillchar='')`:用附加字符填充序列中的字符串到指定的一侧。
             - `width`:结果字符串的最小宽度；其他字符将用空格填充。
             -  我们期望字符串宽度为5。如果小于5，用“0”填充，使其成为“5”。


```python
patients_clean.zip_code = patients_clean.zip_code.astype(str).str[:-2].str.pad(5, fillchar='0') 
patients_clean.zip_code.value_counts()
```




    0000n    12
    12345     6
    30303     4
    10004     4
    15205     3
    98109     3
    90017     3
    10011     3
    60148     3
    35203     3
    11530     3
    70112     3
    01730     3
    11590     3
    40507     2
    95814     2
    10016     2
    39501     2
    13221     2
    19108     2
    02081     2
    12771     2
    73102     2
    97205     2
    02110     2
    02908     2
    95134     2
    23602     2
    94108     2
    12207     2
             ..
    33301     1
    76632     1
    10036     1
    73095     1
    17881     1
    48066     1
    36104     1
    08110     1
    19121     1
    06901     1
    79905     1
    70091     1
    27055     1
    91505     1
    23220     1
    39175     1
    92111     1
    49738     1
    65559     1
    93301     1
    70065     1
    91941     1
    77002     1
    92109     1
    68124     1
    94509     1
    05301     1
    30346     1
    22070     1
    10013     1
    Name: zip_code, Length: 431, dtype: int64



![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/25/1556207488282-1556207488682.png)

- => Reconvert NaNs entries that were converted to '0000n' by code above.
    - np.nan is "NaN" in python


```python
patients_clean.zip_code = patients_clean.zip_code.replace('0000n', np.nan)
patients_clean.head(3)
patients_clean.zip_code.value_counts()
```




    12345    6
    30303    4
    10004    4
    60148    3
    11530    3
    35203    3
    11590    3
    70112    3
    90017    3
    10011    3
    98109    3
    15205    3
    01730    3
    40507    2
    10016    2
    39501    2
    95814    2
    13221    2
    02081    2
    12771    2
    94108    2
    73102    2
    97205    2
    95134    2
    02110    2
    02908    2
    23602    2
    19108    2
    12207    2
    60605    2
            ..
    33301    1
    76632    1
    10036    1
    73095    1
    17881    1
    48066    1
    36104    1
    08110    1
    19121    1
    06901    1
    79905    1
    70091    1
    27055    1
    91505    1
    23220    1
    39175    1
    92111    1
    49738    1
    65559    1
    93301    1
    70065    1
    91941    1
    77002    1
    92109    1
    68124    1
    94509    1
    05301    1
    30346    1
    22070    1
    10013    1
    Name: zip_code, Length: 430, dtype: int64



- `patients` 表: `assigned_sex`, `state`, `zip_code`, and `birthdate` 数据类型错误
- 在`treatments`表中，auranlin and novodra列在开始和结束剂量中带有不必要的字母`u`。
     - => 将`assigned_sex`和`state`转换为分类数据类型。
     上面已经解决了`zip_code`数据类型。
     将“生日”转换为日期时间数据类型。
     在开始剂量和结束剂量中去掉字母`u`，并将这些列转换为数据类型整数。
     - `str()` 单个字符串
     - `.astype(str)` 字符串集

转换为分类类型：`Series.astype('category')`


```python
patients_clean.assigned_sex = patients_clean.assigned_sex.astype('category')
patients_clean.state = patients_clean.state.astype('category')
```

转换为日期格式： `pd.to_datetime(Series)`


```python
patients_clean.birthdate = pd.to_datetime(patients_clean.birthdate)
```


```python
treatments_clean.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hba1c_start</th>
      <th>hba1c_end</th>
      <th>hba1c_change</th>
      <th>treatment</th>
      <th>does_start</th>
      <th>does_end</th>
      <th>does_change</th>
      <th>adverse_reaction</th>
      <th>patient_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.63</td>
      <td>7.20</td>
      <td>0.43</td>
      <td>auralin</td>
      <td>41</td>
      <td>48</td>
      <td>-7</td>
      <td>NaN</td>
      <td>225</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.97</td>
      <td>7.62</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>33</td>
      <td>36</td>
      <td>-3</td>
      <td>NaN</td>
      <td>242</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.65</td>
      <td>7.27</td>
      <td>0.38</td>
      <td>auralin</td>
      <td>37</td>
      <td>42</td>
      <td>-5</td>
      <td>NaN</td>
      <td>345</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.89</td>
      <td>7.55</td>
      <td>0.34</td>
      <td>auralin</td>
      <td>31</td>
      <td>38</td>
      <td>-7</td>
      <td>NaN</td>
      <td>276</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.76</td>
      <td>7.37</td>
      <td>0.39</td>
      <td>auralin</td>
      <td>30</td>
      <td>36</td>
      <td>-6</td>
      <td>NaN</td>
      <td>15</td>
    </tr>
  </tbody>
</table>
</div>




```python
patients_clean.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>assigned_sex</th>
      <th>given_name</th>
      <th>surname</th>
      <th>address</th>
      <th>city</th>
      <th>state</th>
      <th>zip_code</th>
      <th>country</th>
      <th>birthdate</th>
      <th>weight</th>
      <th>height</th>
      <th>bmi</th>
      <th>phone_number</th>
      <th>email</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>female</td>
      <td>Zoe</td>
      <td>Wellish</td>
      <td>576 Brown Bear Drive</td>
      <td>Rancho California</td>
      <td>California</td>
      <td>92390</td>
      <td>United States</td>
      <td>1976-07-10</td>
      <td>121.7</td>
      <td>66</td>
      <td>19.6</td>
      <td>951-719-9170</td>
      <td>ZoeWellish@superrito.com</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>female</td>
      <td>Pamela</td>
      <td>Hill</td>
      <td>2370 University Hill Road</td>
      <td>Armstrong</td>
      <td>Illinois</td>
      <td>61812</td>
      <td>United States</td>
      <td>1967-04-03</td>
      <td>118.8</td>
      <td>66</td>
      <td>19.2</td>
      <td>+1 (217) 569-3204</td>
      <td>PamelaSHill@cuvox.de</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>male</td>
      <td>Jae</td>
      <td>Debord</td>
      <td>1493 Poling Farm Road</td>
      <td>York</td>
      <td>Nebraska</td>
      <td>68467</td>
      <td>United States</td>
      <td>1980-02-19</td>
      <td>177.8</td>
      <td>71</td>
      <td>24.8</td>
      <td>402-363-6804</td>
      <td>JaeMDebord@gustr.com</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>male</td>
      <td>Liêm</td>
      <td>Phan</td>
      <td>2335 Webster Street</td>
      <td>Woodbridge</td>
      <td>NJ</td>
      <td>07095</td>
      <td>United States</td>
      <td>1951-07-26</td>
      <td>220.9</td>
      <td>70</td>
      <td>31.7</td>
      <td>+1 (732) 636-8246</td>
      <td>PhanBaLiem@jourrapide.com</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>male</td>
      <td>Tim</td>
      <td>Neudorf</td>
      <td>1428 Turkey Pen Lane</td>
      <td>Dothan</td>
      <td>AL</td>
      <td>36303</td>
      <td>United States</td>
      <td>1928-02-18</td>
      <td>192.3</td>
      <td>27</td>
      <td>26.1</td>
      <td>334-515-7487</td>
      <td>TimNeudorf@cuvox.de</td>
    </tr>
  </tbody>
</table>
</div>



#### 修复缺失值2

1. 患者身高值不正确（例如，Tim Neudorf身高27英寸而不是72英寸）  
    => 将患者表格中高度为27英寸(只有一个)的行的高度替换为72英寸
    - `Series.replace(oldvalue, newvalue)`
2. state不一致(有时是完整的州名，有时是缩写)  
    => 应用将California, New York, Illinois, Florida, and Nebraska的全名转换为缩写的函数
    - `if Series in DICT.keys():`
    - `df.apply(func, axis=1)`
3. Dsvid 拼写错误，应该是David  
    => 将患者表中给定名称为“Dsvid”的行的名字替换为“David”
    - `Series.replace(oldvalue, newvalue)`
4. 话号码格式不一致  
    => 去掉所有" "、"-"、"("、")和"+"，并存储每个数字，不进行任何格式化。如果电话号码的长度是10位数字(我们需要国家代码)，请用1填充电话号码
    - `Series.str.replace(r'\D+', '').str.pad(11, fillchar='1')`
5. 有不可恢复的无名字的记录  
    => 从患者表中删除不可恢复的John Doe记录记录
    - `df = df[Series != value]`
6. Jakobsen, Gersten, Taylor有多项记录  
     => 将akobsen, Gersten, Taylor从患者表中移除，这些昵称碰巧也不在治疗表中(删除错误的名称会在患者和治疗表之间产生一致性问题)。这些都是重复的第二次出现。这些也是唯一出现的非空重复地址
     - tilde(~) 表示no
     - `df = df[~(Series.duplicated()) & Series.notnull]`
7. Zaitseva的重量用“kgs”而不是“lbs”（磅）  
    => 使用高级索引隔离姓为Zaitseva的行，并将`weight`字段中的条目从kg转换为lbs
    - `df.loc[row_index, column_index] = a value we want`
    - `df.loc[selection criteria, columns i want] = a value we want`
    - `df.loc[selection criteria, a list of cols] df.loc[selection criteria, a list of cols].values(+, -, *, / ... a calculation I want)`

=> 1. 患者身高值不正确（例如，Tim Neudorf身高27英寸而不是72英寸）


```python
patients_clean.height = patients_clean.replace(27, 72)
```

=> 2. 应用将California, New York, Illinois, Florida, and Nebraska的全名转换为缩写的函数


```python
state_abbrev = {'California': 'CA', 
                'New York': 'NY', 
                'Illinois': 'IL', 
                'Florida': 'FL', 
                'Nebraska':'NE'}

def abbreviate_state(df):
    if df['state'] in state_abbrev.keys():
        abbrev = state_abbrev[df['state']]
        return abbrev
    else:
        return df['state']

patients_clean['state'] = patients_clean.apply(abbreviate_state, axis=1)

patients_clean.state.value_counts()
```




    CA    60
    NY    47
    TX    32
    IL    24
    MA    22
    FL    22
    PA    18
    GA    15
    OH    14
    OK    13
    MI    13
    LA    13
    NJ    12
    VA    11
    WI    10
    MS    10
    TN     9
    IN     9
    AL     9
    MN     9
    WA     8
    NC     8
    KY     8
    MO     7
    NE     6
    NV     6
    KS     6
    ID     6
    IA     5
    CT     5
    SC     5
    AR     4
    ND     4
    ME     4
    CO     4
    AZ     4
    RI     4
    DE     3
    SD     3
    WV     3
    MD     3
    OR     3
    MT     2
    VT     2
    DC     2
    AK     1
    NH     1
    WY     1
    NM     1
    Name: state, dtype: int64




```python
patients_clean.state.unique()
```




    array(['CA', 'IL', 'NE', 'NJ', 'AL', 'FL', 'NV', 'MO', 'NY', 'MI', 'TN',
           'VA', 'OK', 'GA', 'MT', 'MA', 'NM', 'LA', 'PA', 'CO', 'ME', 'WI',
           'SD', 'MN', 'WY', 'OH', 'IA', 'NC', 'IN', 'CT', 'KY', 'DE', 'MD',
           'AZ', 'TX', 'AK', 'ND', 'KS', 'MS', 'WA', 'SC', 'WV', 'RI', 'NH',
           'OR', nan, 'VT', 'ID', 'DC', 'AR'], dtype=object)



=> 3. 将患者表中给定名称为“Dsvid”的行的名字替换为“David”


```python
patients_clean.given_name = patients_clean.given_name.replace('Dsvid', 'David')
```

=> 4. 去掉所有" "、"-"、"("、")和"+"，并存储每个数字，不进行任何格式化。如果电话号码的长度是10位数字(我们需要国家代码)，请用1填充电话号码


```python
patients_clean.phone_number = patients_clean.phone_number.str.replace(r'\D+', '').str.pad(11, fillchar='1')
```

=> 5. 从患者表中删除不可恢复的John Doe记录


```python
patients_clean = patients_clean[patients_clean.surname != 'Doe']
```

=> 6. 将akobsen, Gersten, Taylor从患者表中移除，这些昵称碰巧也不在治疗表中


```python
patients_clean = patients_clean[~(patients_clean.address.duplicated()) 
                                & patients_clean.address.notnull()]
```

=> 7. 使用高级索引隔离姓为Zaitseva的行，并将weight字段中的条目从kg转换为lbs


```python
weight_kg = patients_clean.weight.sort_values()[0]
patients_clean.loc[patients_clean.surname == 'Zaitseva', 'weight'] = weight_kg * 2.20462
```


```python
patients_clean.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>patient_id</th>
      <th>assigned_sex</th>
      <th>given_name</th>
      <th>surname</th>
      <th>address</th>
      <th>city</th>
      <th>state</th>
      <th>zip_code</th>
      <th>country</th>
      <th>birthdate</th>
      <th>weight</th>
      <th>height</th>
      <th>bmi</th>
      <th>phone_number</th>
      <th>email</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>female</td>
      <td>Zoe</td>
      <td>Wellish</td>
      <td>576 Brown Bear Drive</td>
      <td>Rancho California</td>
      <td>CA</td>
      <td>92390</td>
      <td>United States</td>
      <td>1976-07-10</td>
      <td>121.7</td>
      <td>1</td>
      <td>19.6</td>
      <td>19517199170</td>
      <td>ZoeWellish@superrito.com</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>female</td>
      <td>Pamela</td>
      <td>Hill</td>
      <td>2370 University Hill Road</td>
      <td>Armstrong</td>
      <td>IL</td>
      <td>61812</td>
      <td>United States</td>
      <td>1967-04-03</td>
      <td>118.8</td>
      <td>2</td>
      <td>19.2</td>
      <td>12175693204</td>
      <td>PamelaSHill@cuvox.de</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>male</td>
      <td>Jae</td>
      <td>Debord</td>
      <td>1493 Poling Farm Road</td>
      <td>York</td>
      <td>NE</td>
      <td>68467</td>
      <td>United States</td>
      <td>1980-02-19</td>
      <td>177.8</td>
      <td>3</td>
      <td>24.8</td>
      <td>14023636804</td>
      <td>JaeMDebord@gustr.com</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>male</td>
      <td>Liêm</td>
      <td>Phan</td>
      <td>2335 Webster Street</td>
      <td>Woodbridge</td>
      <td>NJ</td>
      <td>07095</td>
      <td>United States</td>
      <td>1951-07-26</td>
      <td>220.9</td>
      <td>4</td>
      <td>31.7</td>
      <td>17326368246</td>
      <td>PhanBaLiem@jourrapide.com</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>male</td>
      <td>Tim</td>
      <td>Neudorf</td>
      <td>1428 Turkey Pen Lane</td>
      <td>Dothan</td>
      <td>AL</td>
      <td>36303</td>
      <td>United States</td>
      <td>1928-02-18</td>
      <td>192.3</td>
      <td>5</td>
      <td>26.1</td>
      <td>13345157487</td>
      <td>TimNeudorf@cuvox.de</td>
    </tr>
  </tbody>
</table>
</div>




```python
treatments_clean.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hba1c_start</th>
      <th>hba1c_end</th>
      <th>hba1c_change</th>
      <th>treatment</th>
      <th>does_start</th>
      <th>does_end</th>
      <th>does_change</th>
      <th>adverse_reaction</th>
      <th>patient_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.63</td>
      <td>7.20</td>
      <td>0.43</td>
      <td>auralin</td>
      <td>41</td>
      <td>48</td>
      <td>-7</td>
      <td>NaN</td>
      <td>225</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.97</td>
      <td>7.62</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>33</td>
      <td>36</td>
      <td>-3</td>
      <td>NaN</td>
      <td>242</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.65</td>
      <td>7.27</td>
      <td>0.38</td>
      <td>auralin</td>
      <td>37</td>
      <td>42</td>
      <td>-5</td>
      <td>NaN</td>
      <td>345</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.89</td>
      <td>7.55</td>
      <td>0.34</td>
      <td>auralin</td>
      <td>31</td>
      <td>38</td>
      <td>-7</td>
      <td>NaN</td>
      <td>276</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.76</td>
      <td>7.37</td>
      <td>0.39</td>
      <td>auralin</td>
      <td>30</td>
      <td>36</td>
      <td>-6</td>
      <td>NaN</td>
      <td>15</td>
    </tr>
  </tbody>
</table>
</div>




```python
treatments_clean.to_csv('treatments_final.csv', index=False)
```


```python
treatments_final = pd.read_csv('treatments_final.csv')
treatments_final
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hba1c_start</th>
      <th>hba1c_end</th>
      <th>hba1c_change</th>
      <th>treatment</th>
      <th>does_start</th>
      <th>does_end</th>
      <th>does_change</th>
      <th>adverse_reaction</th>
      <th>patient_id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.63</td>
      <td>7.20</td>
      <td>0.43</td>
      <td>auralin</td>
      <td>41</td>
      <td>48</td>
      <td>-7</td>
      <td>NaN</td>
      <td>225</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.97</td>
      <td>7.62</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>33</td>
      <td>36</td>
      <td>-3</td>
      <td>NaN</td>
      <td>242</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.65</td>
      <td>7.27</td>
      <td>0.38</td>
      <td>auralin</td>
      <td>37</td>
      <td>42</td>
      <td>-5</td>
      <td>NaN</td>
      <td>345</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.89</td>
      <td>7.55</td>
      <td>0.34</td>
      <td>auralin</td>
      <td>31</td>
      <td>38</td>
      <td>-7</td>
      <td>NaN</td>
      <td>276</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7.76</td>
      <td>7.37</td>
      <td>0.39</td>
      <td>auralin</td>
      <td>30</td>
      <td>36</td>
      <td>-6</td>
      <td>NaN</td>
      <td>15</td>
    </tr>
    <tr>
      <th>5</th>
      <td>7.70</td>
      <td>7.19</td>
      <td>0.51</td>
      <td>auralin</td>
      <td>29</td>
      <td>36</td>
      <td>-7</td>
      <td>hypoglycemia</td>
      <td>70</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7.70</td>
      <td>7.19</td>
      <td>0.51</td>
      <td>auralin</td>
      <td>29</td>
      <td>36</td>
      <td>-7</td>
      <td>hypoglycemia</td>
      <td>70</td>
    </tr>
    <tr>
      <th>7</th>
      <td>9.54</td>
      <td>9.14</td>
      <td>0.40</td>
      <td>auralin</td>
      <td>29</td>
      <td>38</td>
      <td>-9</td>
      <td>NaN</td>
      <td>18</td>
    </tr>
    <tr>
      <th>8</th>
      <td>7.74</td>
      <td>7.30</td>
      <td>0.44</td>
      <td>auralin</td>
      <td>27</td>
      <td>37</td>
      <td>-10</td>
      <td>NaN</td>
      <td>424</td>
    </tr>
    <tr>
      <th>9</th>
      <td>7.78</td>
      <td>7.34</td>
      <td>0.44</td>
      <td>auralin</td>
      <td>55</td>
      <td>68</td>
      <td>-13</td>
      <td>NaN</td>
      <td>292</td>
    </tr>
    <tr>
      <th>10</th>
      <td>7.53</td>
      <td>7.13</td>
      <td>0.40</td>
      <td>auralin</td>
      <td>28</td>
      <td>37</td>
      <td>-9</td>
      <td>NaN</td>
      <td>211</td>
    </tr>
    <tr>
      <th>11</th>
      <td>7.61</td>
      <td>7.29</td>
      <td>0.32</td>
      <td>auralin</td>
      <td>29</td>
      <td>39</td>
      <td>-10</td>
      <td>NaN</td>
      <td>133</td>
    </tr>
    <tr>
      <th>12</th>
      <td>8.61</td>
      <td>8.18</td>
      <td>0.43</td>
      <td>auralin</td>
      <td>53</td>
      <td>60</td>
      <td>-7</td>
      <td>NaN</td>
      <td>316</td>
    </tr>
    <tr>
      <th>13</th>
      <td>9.68</td>
      <td>9.29</td>
      <td>0.39</td>
      <td>auralin</td>
      <td>31</td>
      <td>41</td>
      <td>-10</td>
      <td>NaN</td>
      <td>101</td>
    </tr>
    <tr>
      <th>14</th>
      <td>7.79</td>
      <td>7.40</td>
      <td>0.39</td>
      <td>auralin</td>
      <td>42</td>
      <td>51</td>
      <td>-9</td>
      <td>throat irritation</td>
      <td>451</td>
    </tr>
    <tr>
      <th>15</th>
      <td>7.81</td>
      <td>7.48</td>
      <td>0.33</td>
      <td>auralin</td>
      <td>42</td>
      <td>49</td>
      <td>-7</td>
      <td>NaN</td>
      <td>335</td>
    </tr>
    <tr>
      <th>16</th>
      <td>7.70</td>
      <td>7.38</td>
      <td>0.32</td>
      <td>auralin</td>
      <td>35</td>
      <td>39</td>
      <td>-4</td>
      <td>NaN</td>
      <td>389</td>
    </tr>
    <tr>
      <th>17</th>
      <td>7.96</td>
      <td>7.55</td>
      <td>0.41</td>
      <td>auralin</td>
      <td>47</td>
      <td>58</td>
      <td>-11</td>
      <td>NaN</td>
      <td>71</td>
    </tr>
    <tr>
      <th>18</th>
      <td>7.68</td>
      <td>7.24</td>
      <td>0.44</td>
      <td>auralin</td>
      <td>45</td>
      <td>48</td>
      <td>-3</td>
      <td>NaN</td>
      <td>297</td>
    </tr>
    <tr>
      <th>19</th>
      <td>7.92</td>
      <td>7.47</td>
      <td>0.45</td>
      <td>auralin</td>
      <td>24</td>
      <td>37</td>
      <td>-13</td>
      <td>NaN</td>
      <td>188</td>
    </tr>
    <tr>
      <th>20</th>
      <td>7.92</td>
      <td>7.57</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>44</td>
      <td>55</td>
      <td>-11</td>
      <td>NaN</td>
      <td>282</td>
    </tr>
    <tr>
      <th>21</th>
      <td>7.53</td>
      <td>7.15</td>
      <td>0.38</td>
      <td>auralin</td>
      <td>37</td>
      <td>43</td>
      <td>-6</td>
      <td>NaN</td>
      <td>174</td>
    </tr>
    <tr>
      <th>22</th>
      <td>7.67</td>
      <td>7.37</td>
      <td>0.30</td>
      <td>auralin</td>
      <td>43</td>
      <td>47</td>
      <td>-4</td>
      <td>NaN</td>
      <td>146</td>
    </tr>
    <tr>
      <th>23</th>
      <td>7.86</td>
      <td>7.51</td>
      <td>0.35</td>
      <td>auralin</td>
      <td>36</td>
      <td>42</td>
      <td>-6</td>
      <td>NaN</td>
      <td>35</td>
    </tr>
    <tr>
      <th>24</th>
      <td>9.18</td>
      <td>8.64</td>
      <td>0.54</td>
      <td>auralin</td>
      <td>29</td>
      <td>37</td>
      <td>-8</td>
      <td>NaN</td>
      <td>350</td>
    </tr>
    <tr>
      <th>25</th>
      <td>7.61</td>
      <td>7.16</td>
      <td>0.45</td>
      <td>auralin</td>
      <td>57</td>
      <td>64</td>
      <td>-7</td>
      <td>NaN</td>
      <td>220</td>
    </tr>
    <tr>
      <th>26</th>
      <td>7.52</td>
      <td>7.11</td>
      <td>0.41</td>
      <td>auralin</td>
      <td>54</td>
      <td>67</td>
      <td>-13</td>
      <td>NaN</td>
      <td>102</td>
    </tr>
    <tr>
      <th>27</th>
      <td>7.71</td>
      <td>7.34</td>
      <td>0.37</td>
      <td>auralin</td>
      <td>34</td>
      <td>42</td>
      <td>-8</td>
      <td>NaN</td>
      <td>181</td>
    </tr>
    <tr>
      <th>28</th>
      <td>7.87</td>
      <td>7.47</td>
      <td>0.40</td>
      <td>auralin</td>
      <td>29</td>
      <td>37</td>
      <td>-8</td>
      <td>NaN</td>
      <td>466</td>
    </tr>
    <tr>
      <th>29</th>
      <td>7.74</td>
      <td>7.32</td>
      <td>0.42</td>
      <td>auralin</td>
      <td>61</td>
      <td>67</td>
      <td>-6</td>
      <td>NaN</td>
      <td>205</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>249</th>
      <td>7.98</td>
      <td>7.51</td>
      <td>0.47</td>
      <td>novodra</td>
      <td>37</td>
      <td>30</td>
      <td>7</td>
      <td>NaN</td>
      <td>309</td>
    </tr>
    <tr>
      <th>250</th>
      <td>7.92</td>
      <td>7.47</td>
      <td>0.45</td>
      <td>novodra</td>
      <td>51</td>
      <td>47</td>
      <td>4</td>
      <td>NaN</td>
      <td>400</td>
    </tr>
    <tr>
      <th>251</th>
      <td>9.53</td>
      <td>9.10</td>
      <td>0.43</td>
      <td>novodra</td>
      <td>27</td>
      <td>29</td>
      <td>-2</td>
      <td>NaN</td>
      <td>2</td>
    </tr>
    <tr>
      <th>252</th>
      <td>7.62</td>
      <td>7.22</td>
      <td>0.40</td>
      <td>novodra</td>
      <td>42</td>
      <td>44</td>
      <td>-2</td>
      <td>NaN</td>
      <td>147</td>
    </tr>
    <tr>
      <th>253</th>
      <td>7.89</td>
      <td>7.53</td>
      <td>0.36</td>
      <td>novodra</td>
      <td>30</td>
      <td>29</td>
      <td>1</td>
      <td>NaN</td>
      <td>447</td>
    </tr>
    <tr>
      <th>254</th>
      <td>8.82</td>
      <td>8.36</td>
      <td>0.46</td>
      <td>novodra</td>
      <td>31</td>
      <td>32</td>
      <td>-1</td>
      <td>NaN</td>
      <td>329</td>
    </tr>
    <tr>
      <th>255</th>
      <td>7.97</td>
      <td>7.52</td>
      <td>0.45</td>
      <td>novodra</td>
      <td>48</td>
      <td>53</td>
      <td>-5</td>
      <td>NaN</td>
      <td>300</td>
    </tr>
    <tr>
      <th>256</th>
      <td>7.96</td>
      <td>7.62</td>
      <td>0.34</td>
      <td>novodra</td>
      <td>42</td>
      <td>40</td>
      <td>2</td>
      <td>NaN</td>
      <td>108</td>
    </tr>
    <tr>
      <th>257</th>
      <td>7.78</td>
      <td>7.42</td>
      <td>0.36</td>
      <td>novodra</td>
      <td>28</td>
      <td>24</td>
      <td>4</td>
      <td>NaN</td>
      <td>364</td>
    </tr>
    <tr>
      <th>258</th>
      <td>7.97</td>
      <td>7.59</td>
      <td>0.38</td>
      <td>novodra</td>
      <td>51</td>
      <td>54</td>
      <td>-3</td>
      <td>NaN</td>
      <td>289</td>
    </tr>
    <tr>
      <th>259</th>
      <td>7.92</td>
      <td>7.49</td>
      <td>0.43</td>
      <td>novodra</td>
      <td>47</td>
      <td>39</td>
      <td>8</td>
      <td>NaN</td>
      <td>387</td>
    </tr>
    <tr>
      <th>260</th>
      <td>7.61</td>
      <td>7.12</td>
      <td>0.49</td>
      <td>novodra</td>
      <td>47</td>
      <td>48</td>
      <td>-1</td>
      <td>NaN</td>
      <td>454</td>
    </tr>
    <tr>
      <th>261</th>
      <td>7.78</td>
      <td>7.45</td>
      <td>0.33</td>
      <td>novodra</td>
      <td>39</td>
      <td>36</td>
      <td>3</td>
      <td>injection site discomfort</td>
      <td>255</td>
    </tr>
    <tr>
      <th>262</th>
      <td>7.90</td>
      <td>7.51</td>
      <td>0.39</td>
      <td>novodra</td>
      <td>56</td>
      <td>57</td>
      <td>-1</td>
      <td>NaN</td>
      <td>84</td>
    </tr>
    <tr>
      <th>263</th>
      <td>9.62</td>
      <td>9.29</td>
      <td>0.33</td>
      <td>novodra</td>
      <td>42</td>
      <td>38</td>
      <td>4</td>
      <td>NaN</td>
      <td>239</td>
    </tr>
    <tr>
      <th>264</th>
      <td>9.27</td>
      <td>8.77</td>
      <td>0.50</td>
      <td>novodra</td>
      <td>40</td>
      <td>39</td>
      <td>1</td>
      <td>NaN</td>
      <td>158</td>
    </tr>
    <tr>
      <th>265</th>
      <td>7.89</td>
      <td>7.42</td>
      <td>0.47</td>
      <td>novodra</td>
      <td>39</td>
      <td>36</td>
      <td>3</td>
      <td>NaN</td>
      <td>139</td>
    </tr>
    <tr>
      <th>266</th>
      <td>8.50</td>
      <td>8.10</td>
      <td>0.40</td>
      <td>novodra</td>
      <td>27</td>
      <td>28</td>
      <td>-1</td>
      <td>NaN</td>
      <td>343</td>
    </tr>
    <tr>
      <th>267</th>
      <td>7.71</td>
      <td>7.27</td>
      <td>0.44</td>
      <td>novodra</td>
      <td>43</td>
      <td>46</td>
      <td>-3</td>
      <td>NaN</td>
      <td>330</td>
    </tr>
    <tr>
      <th>268</th>
      <td>7.64</td>
      <td>7.33</td>
      <td>0.31</td>
      <td>novodra</td>
      <td>31</td>
      <td>31</td>
      <td>0</td>
      <td>NaN</td>
      <td>405</td>
    </tr>
    <tr>
      <th>269</th>
      <td>7.87</td>
      <td>7.47</td>
      <td>0.40</td>
      <td>novodra</td>
      <td>26</td>
      <td>23</td>
      <td>3</td>
      <td>NaN</td>
      <td>281</td>
    </tr>
    <tr>
      <th>270</th>
      <td>7.63</td>
      <td>7.27</td>
      <td>0.36</td>
      <td>novodra</td>
      <td>50</td>
      <td>54</td>
      <td>-4</td>
      <td>NaN</td>
      <td>92</td>
    </tr>
    <tr>
      <th>271</th>
      <td>7.95</td>
      <td>7.56</td>
      <td>0.39</td>
      <td>novodra</td>
      <td>41</td>
      <td>39</td>
      <td>2</td>
      <td>NaN</td>
      <td>365</td>
    </tr>
    <tr>
      <th>272</th>
      <td>7.83</td>
      <td>7.48</td>
      <td>0.35</td>
      <td>novodra</td>
      <td>27</td>
      <td>29</td>
      <td>-2</td>
      <td>NaN</td>
      <td>453</td>
    </tr>
    <tr>
      <th>273</th>
      <td>7.72</td>
      <td>7.29</td>
      <td>0.43</td>
      <td>novodra</td>
      <td>38</td>
      <td>32</td>
      <td>6</td>
      <td>injection site discomfort</td>
      <td>332</td>
    </tr>
    <tr>
      <th>274</th>
      <td>7.82</td>
      <td>7.36</td>
      <td>0.46</td>
      <td>novodra</td>
      <td>51</td>
      <td>54</td>
      <td>-3</td>
      <td>NaN</td>
      <td>59</td>
    </tr>
    <tr>
      <th>275</th>
      <td>7.77</td>
      <td>7.28</td>
      <td>0.49</td>
      <td>novodra</td>
      <td>47</td>
      <td>46</td>
      <td>1</td>
      <td>NaN</td>
      <td>440</td>
    </tr>
    <tr>
      <th>276</th>
      <td>7.74</td>
      <td>7.36</td>
      <td>0.38</td>
      <td>novodra</td>
      <td>30</td>
      <td>33</td>
      <td>-3</td>
      <td>NaN</td>
      <td>434</td>
    </tr>
    <tr>
      <th>277</th>
      <td>7.87</td>
      <td>7.43</td>
      <td>0.44</td>
      <td>novodra</td>
      <td>41</td>
      <td>43</td>
      <td>-2</td>
      <td>headache</td>
      <td>394</td>
    </tr>
    <tr>
      <th>278</th>
      <td>7.90</td>
      <td>7.58</td>
      <td>0.32</td>
      <td>novodra</td>
      <td>49</td>
      <td>49</td>
      <td>0</td>
      <td>NaN</td>
      <td>141</td>
    </tr>
  </tbody>
</table>
<p>279 rows × 9 columns</p>
</div>




```python
adverse_reactions_clean.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>given_name</th>
      <th>surname</th>
      <th>adverse_reaction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>berta</td>
      <td>napolitani</td>
      <td>injection site discomfort</td>
    </tr>
    <tr>
      <th>1</th>
      <td>lena</td>
      <td>baer</td>
      <td>hypoglycemia</td>
    </tr>
    <tr>
      <th>2</th>
      <td>joseph</td>
      <td>day</td>
      <td>hypoglycemia</td>
    </tr>
    <tr>
      <th>3</th>
      <td>flavia</td>
      <td>fiorentino</td>
      <td>cough</td>
    </tr>
    <tr>
      <th>4</th>
      <td>manouck</td>
      <td>wubbels</td>
      <td>throat irritation</td>
    </tr>
  </tbody>
</table>
</div>




```python
id_names = patients_clean[['patient_id', 'given_name', 'surname']]
id_names['given_name'] = id_names['given_name'].str.lower()
id_names['surname'] = id_names['surname'].str.lower()
adverse_reactions_clean = pd.merge(adverse_reactions_clean, id_names, on=['given_name', 'surname'])
# adverse_reactions_clean = adverse_reactions_clean.drop(['given_name', 'surname'], axis=1)
```

    E:\ProgramData\Anaconda3\envs\data_analysis\lib\site-packages\ipykernel_launcher.py:2: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      
    E:\ProgramData\Anaconda3\envs\data_analysis\lib\site-packages\ipykernel_launcher.py:3: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      This is separate from the ipykernel package so we can avoid doing imports until



```python
treatment_group = treatments_final.groupby('treatment')
treatment_group
```




    <pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000027A8D126CC0>




```python
treatment_group.mean()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hba1c_start</th>
      <th>hba1c_end</th>
      <th>hba1c_change</th>
      <th>does_start</th>
      <th>does_end</th>
      <th>does_change</th>
      <th>patient_id</th>
    </tr>
    <tr>
      <th>treatment</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>auralin</th>
      <td>7.999927</td>
      <td>7.613942</td>
      <td>0.385985</td>
      <td>39.335766</td>
      <td>47.547445</td>
      <td>-8.211679</td>
      <td>256.233577</td>
    </tr>
    <tr>
      <th>novodra</th>
      <td>7.974296</td>
      <td>7.567676</td>
      <td>0.406620</td>
      <td>39.929577</td>
      <td>39.471831</td>
      <td>0.457746</td>
      <td>263.563380</td>
    </tr>
  </tbody>
</table>
</div>




```python
Auralin = treatment_group.mean().loc['auralin', 'does_change']
Novodra = treatment_group.mean().loc['novodra', 'does_change']
```


```python
import matplotlib.pyplot as plt 
import seaborn as sns
sns.set_style('darkgrid')
```


```python
%matplotlib inline
plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号
```


```python
treatment_group.mean().does_change.plot(kind='bar', title='实验前/后胰岛素平均计量变化')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x27a8e6a2748>




![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/28/output_87_1-1556460272812.png)



```python
treatment_group.mean().hba1c_change.plot(kind='bar', title='实验前/后hba1c变化量均值')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x27a8e999cc0>




![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/28/output_88_1-1556460290256.png)



```python
treatment_group.mean().info()
```

    <class 'pandas.core.frame.DataFrame'>
    Index: 2 entries, auralin to novodra
    Data columns (total 7 columns):
    hba1c_start     2 non-null float64
    hba1c_end       2 non-null float64
    hba1c_change    2 non-null float64
    does_start      2 non-null float64
    does_end        2 non-null float64
    does_change     2 non-null float64
    patient_id      2 non-null float64
    dtypes: float64(7)
    memory usage: 208.0+ bytes



```python
after_adverse_reactions = treatment_group['adverse_reaction'].value_counts()
after_adverse_reactions
```




    treatment  adverse_reaction         
    auralin    hypoglycemia                 9
               throat irritation            2
               headache                     1
               nausea                       1
    novodra    hypoglycemia                 9
               headache                     2
               injection site discomfort    2
               cough                        1
    Name: adverse_reaction, dtype: int64




```python
after_adverse_reactions.unstack()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>adverse_reaction</th>
      <th>cough</th>
      <th>headache</th>
      <th>hypoglycemia</th>
      <th>injection site discomfort</th>
      <th>nausea</th>
      <th>throat irritation</th>
    </tr>
    <tr>
      <th>treatment</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>auralin</th>
      <td>NaN</td>
      <td>1.0</td>
      <td>9.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>novodra</th>
      <td>1.0</td>
      <td>2.0</td>
      <td>9.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
after_adverse_reactions.unstack().plot(kind='bar', figsize=(20, 4))
```




    <matplotlib.axes._subplots.AxesSubplot at 0x27a8f9fae80>




![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/28/output_92_1-1556460315842.png)



```python
after_adverse_reactions.auralin.plot(kind='bar', figsize=(20, 4), title='Auralin不良反应')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x27a8e999470>




![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/28/output_93_1-1556460342208.png)



```python
after_adverse_reactions.novodra.plot(kind='bar', figsize=(20, 4), title='Novodra不良反应')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x27a8faa45f8>




![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/28/output_94_1-1556460355784.png)


对比下面的循环遍历，Groupby能让我们直接免去循环, 而且不需要烦人的筛选, 一行就完美搞定


```python
ts = np.sort(treatments_final['treatment'].dropna().unique())
fig, axes = plt.subplots(1, len(ts), figsize = (24, 4), sharey=True)
for ax, t in zip(axes, ts):
    treatments_final[treatments_final['treatment'] == t]['adverse_reaction'].value_counts().sort_index().plot(kind='bar', ax=ax, title=t)

```


![title](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/gitnote/2019/04/28/output_96_0-1556460372695.png)

